# import dependencies
import os
import re
import json
import time
import requests
import pandas as pd, numpy as np
from selenium import webdriver
from bs4 import BeautifulSoup as bs
from urllib.request import urlopen
from pandas.io.json import json_normalize

# open web browser to tag feed
hashtag = input("#")
browser = webdriver.Chrome(r'C:\Users\CommTech\PycharmProjects\Work Projects\chromedriver.exe')
browser.get('https://www.instagram.com/explore/tags/'+hashtag)
page_length = browser.execute_script("window.scrollTo(0, document.body.scrollHeight);")

# parse HTML source page
page_length = browser.execute_script("window.scrollTo(0, document.body.scrollHeight/1.5);")
links = []
source = browser.page_source
data = bs(source, 'html.parser')
body = data.find('body')
script = body.find('span')
for link in script.findAll('a'):
    if re.match("/p", link.get('href')):
        links.append('https://www.instagram.com'+link.get('href'))

time.sleep(5) # sleep time is required, otherwise Instagram may interrupt the script and won't scroll through pages

page_length = browser.execute_script("window.scrollTo(0, document.body.scrollHeight/1.5, document.body.scrollHeight/3.0);")
source = browser.page_source
data = bs(source, 'html.parser')
body = data.find('body')
script = body.find('span')
for link in script.findAll('a'):
    if re.match("/p", link.get('href')):
        links.append('https://www.instagram.com'+link.get('href'))

# get information for each image/post in the page
result = pd.DataFrame()
for i in range(len(links)):
    try:
        page = urlopen(links[i]).read()
        data = bs(page, 'html.parser')
        body = data.find('body')
        script = body.find('script')
        raw = script.text.strip().replace('window._sharedData =', '').replace(';', '')
        json_data = json.loads(raw)
        posts = json_data['entry_data']['PostPage'][0]['graphql']
        posts = json.dumps(posts)
        posts = json.loads(posts)
        x = pd.DataFrame.from_dict(json_normalize(posts), orient = 'columns')
        x_columns = x.columns.str.replace("shortcode_media.", "")
        result = result.append(x)
    except:
        np.nan

sort=True
